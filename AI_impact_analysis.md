# AI impact analysis - 2026/01

## My thoughts:

- LLM model is based on transformer and mostly trained with text information
[reference: transformer](https://arxiv.org/abs/1706.03762)

- It is a probability model and results are not 100% guaranteed

- AGI cannot be achieved purely by text and image training, since human knowledge are gained not only in text but also in other format: vision, smell, touch...
Some AI experts argues that LLM is a dead end and world model is required:

    [reference 1](https://garymarcus.substack.com/p/generative-ais-crippling-and-widespread)

    [reference 2 by Yann LeCun, not the original post](https://eu.36kr.com/en/p/3571987975018880#:~:text=In%20terms%20of%20learning%20methods,the%20core%20of%20action%20intelligence.)

- LLM trained by data generated by LLM see performances degradation (model collapse). If LLM is true intelligent, then its generated data should have same quality as the real human generated data

    [reference: the paper](https://www.nature.com/articles/s41586-025-08905-3)
    [reason for the collapse](https://arxiv.org/html/2402.07712v1)

- Current model has exhausted fresh human generated data
    [human generated text data maybe exhausted](https://arxiv.org/abs/2211.04325v2)

## Questions:

- Do we need to learn in the future, since you cannot be "smarter" and more knowledgeable than AI?

- Who will be replaced by AI? Is software industry dying and no longer need programmers?

- How do we survive in a AI world? What should we do?

## Short term: 1-5 years


## Mid term: 5-10 years

## Long term: 10 years and more